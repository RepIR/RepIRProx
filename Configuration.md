About configuration files (typically in `rr/settings`)

A configuration file describes the settings for a repository, test set, parameters for modules, etc. These configuration files can import other configuration files to avoid redundancy.

For example, `trec1` contains the settings for the trec1 collection, trec1 adhoc test set, etc. To create and use the repository, you need the TREC1 dataset (license required), topic and qrel files (downloads from TREC website). In trec1, `repository.inputdir` must point to the location of the original collection files on HDFS. `repository.dir` must point to the location where the repository is stored, for which the root directory (e.g. `/user/jeroenv/output/trec1`) must exist.

These configuration files can import other configuration files to avoid redundancy. e.g. `trec1` imports `trec` which adds configuration to skip non-document files in the collection, declares the features to extract and store in the repository, that the repository will contain only one partition and that terms that occur less than 2 times in the collection are ignored. Configurations that need a similar setup (e.g. trec4, 5, 6 and 7) import the same `trec` defaults.

The general settings for the cluster are stored in `clustersettings`, which should be imported by default (in `trec`). Note that you do not need a seperate file for these settings, it is convenient to store static and default settings in one place, and you can always override these settings. Some settings, like the jars that ned to be included on MapReduce jobs are not trivial and rather crucial for the proper operation of RepIR. In clustersettings, these jars are added to `rr.lib`, so it is crucial to check these have the right location. In `clustersettings`, you also see `${}` references, which are resolved when the settings are used, therefore the order of parameters is not important and they can be overridden in later configuration lines or java.

Components in RepIR are highly configurable, to allow reuse with minimal coding. For instance, the default `RepositoryBuilder` reads archive files from the collection source folders, and stores extracted features in the repository. The configuration file will assign an `repository.entityreader` which knows how to read entities (documents) from the collection archives. The extraction process is by default handled by an extractor which for the `tiny` collection is configured in `tinytokenizer`. The extractor uses SectionMarker's to mark section of some type in an entity's raw input data, and per type executes a chain of modules process the section into entity attributes. The Feature's that have been declared get to inspect each entity, extracting their value from the entities attributes. The javadoc for each module should describe the configuration options.

Note: most tools allow you to override any configuration setting from the commandline, by adding var.name=xxx on the command line. e.g. `qq tiny Albert Einstein kld.mu=2500` will retrieve results with a different setting for kld.mu than the configured default. This also applies to any Hadoop setting, e.g. `testset tiny kld mapred.job.priority=HIGH` will run with the given job priority.
